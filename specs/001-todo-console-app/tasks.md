---

description: "Task list for Todo Console Application Phase 1 implementation"

---

# Tasks: Todo Console Application (Phase 1)

**Input**: Design documents from `/specs/001-todo-console-app/`
**Prerequisites**: plan.md (required), spec.md (required for user stories), research.md, data-model.md, contracts/
**Project**: Todo App (Hackathon II) | Phase: I - In-Memory Python Console Application
**Tech Stack**: Python 3.13+, UV, Claude Code, Spec-Kit Plus
**Rule**: No manual coding. All code must be generated by Claude Code via Spec-Kit Plus.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions
- Reference spec sections and Task IDs in code comments

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization and basic structure

- [ ] **T-001** [P] Initialize UV project with Python 3.13+ in `src/`
  - Create pyproject.toml with project metadata
  - Create .python-version file
  - Create src/ directory structure per plan.md
  - Create placeholder Python modules: `__init__.py`, `main.py`, `ui.py`, `models.py`, `memory.py`, `services.py`
  - **Acceptance**: Project runs with `uv run src/main.py`
  - **Spec Ref**: sp.constitution Â§Python Excellence, sp.plan Â§Project Structure

- [ ] **T-002** [P] Configure linting and formatting tools
  - Configure ruff or flake8 for linting
  - Configure black or ruff format for formatting
  - Configure mypy for type checking
  - **Acceptance**: All tools pass on initial code
  - **Spec Ref**: sp.constitution Â§II. Python Excellence Standard

- [ ] **T-003** [P] Create test infrastructure
  - Create tests/ directory with unit/ and integration/ subdirectories
  - Create conftest.py with pytest fixtures
  - Configure pytest-cov for coverage reporting
  - **Acceptance**: Tests run with `pytest` and show 0% coverage initially
  - **Spec Ref**: sp.constitution Â§III. TDD Mandatory

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**CRITICAL**: No user story work can begin until this phase is complete

- [ ] **T-004** Create Task domain model in `src/models/task.py`
  - Define Task dataclass with fields: id, title, description, completed, created_at, updated_at
  - Add validation methods for title (1-200 chars) and description (max 1000 chars)
  - Add business methods: update_title(), mark_complete(), mark_incomplete()
  - Add docstrings using Google style
  - **Acceptance**: Task dataclass passes type checking, all fields validated
  - **Spec Ref**: sp.specify Â§Task Entity, sp.data-model.md Â§Task Entity

- [ ] **T-005** Implement in-memory storage in `src/memory.py`
  - Create MemoryAgent class with dict-based storage
  - Implement add, retrieve, update, delete operations
  - Implement auto-incrementing ID generation (starts at 1)
  - **Acceptance**: Storage is in-memory only, resets on restart
  - **Spec Ref**: sp.specify Â§In-Memory Storage, sp.research.md Â§Data Storage Strategy

- [ ] **T-006** Create custom exceptions in `src/exceptions.py`
  - Define TodoError base exception
  - Define TaskNotFoundError, InvalidTitleError, TaskAlreadyCompletedError
  - **Acceptance**: All exceptions inherit from TodoError with appropriate messages
  - **Spec Ref**: sp.research.md Â§Error Handling Strategy

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - Add Tasks (Priority: P1) ðŸŽ¯ MVP

**Goal**: Users can add new tasks with title and optional description

**Independent Test**: Run `todo add "Test task"` and verify task appears in `todo list`

### Tests for User Story 1

> **NOTE: Write these tests FIRST, ensure they FAIL before implementation**

- [ ] **T-007** [P] [US1] Unit test for Task creation in `tests/unit/test_task.py`
  - Test task creation with title only
  - Test task creation with title and description
  - Test auto-generated ID
  - Test auto-timestamps
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-008** [P] [US1] Unit test for MemoryAgent add in `tests/unit/test_memory.py`
  - Test add task returns task with ID
  - Test add task with description
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-009** [US1] Integration test for add command in `tests/integration/test_cli.py`
  - Test `todo add "Buy groceries"` creates task
  - Test `todo add "Buy" -d "Milk"` creates task with description
  - **Acceptance**: All tests FAIL before implementation

### Implementation for User Story 1

- [ ] **T-010** [P] [US1] Create TaskService.add_task() in `src/services/task_service.py`
  - Validate title (1-200 chars)
  - Validate description (max 1000 chars)
  - Generate ID via MemoryAgent
  - Create and save Task
  - Return created Task
  - **Acceptance**: add_task() creates valid task, raises InvalidTitleError for invalid input
  - **Spec Ref**: sp.specify Â§FR-001, FR-002, FR-003, FR-010, FR-011

- [ ] **T-011** [US1] Implement add command handler in `src/cli/commands.py`
  - Parse title argument
  - Parse -d/--description option
  - Call TaskService.add_task()
  - Display success message with task ID
  - **Acceptance**: `todo add "Title"` creates task and shows confirmation
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo add

- [ ] **T-012** [US1] Register add subparser in `src/cli/parser.py`
  - Add "add" subcommand to argparse
  - Add required positional "title" argument
  - Add optional -d/--description flag
  - Set up help messages
  - **Acceptance**: `todo add --help` shows correct usage
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo add

**Checkpoint**: User Story 1 complete - users can add tasks

---

## Phase 4: User Story 2 - List Tasks (Priority: P1)

**Goal**: Users can view all tasks with optional filtering by completion status

**Independent Test**: Add tasks, run `todo list` and `todo list --completed`, verify output

### Tests for User Story 2

- [ ] **T-013** [P] [US2] Unit test for TaskService.list_tasks() in `tests/unit/test_task_service.py`
  - Test list all returns all tasks
  - Test list with completed filter
  - Test list with pending filter
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-014** [US2] Integration test for list command in `tests/integration/test_cli.py`
  - Test `todo list` shows all tasks
  - Test `todo list --completed` shows only completed
  - Test `todo list --pending` shows only pending
  - Test empty list shows appropriate message
  - **Acceptance**: All tests FAIL before implementation

### Implementation for User Story 2

- [ ] **T-015** [P] [US2] Create TaskService.list_tasks() in `src/services/task_service.py`
  - Return all tasks if no filter
  - Return filtered tasks by completed status
  - Sort tasks by ID
  - **Acceptance**: list_tasks() returns correct tasks based on filter
  - **Spec Ref**: sp.specify Â§FR-004, FR-005

- [ ] **T-016** [US2] Implement list command handler in `src/cli/commands.py`
  - Check for --completed/--pending flags
  - Call TaskService.list_tasks()
  - Format and display task table
  - Handle empty list case
  - **Acceptance**: `todo list` displays formatted task table
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo list

- [ ] **T-017** [US2] Register list subparser in `src/cli/parser.py`
  - Add "list" subcommand
  - Add --completed and --pending flags
  - **Acceptance**: `todo list --help` shows correct options
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo list

**Checkpoint**: User Story 2 complete - users can list tasks

---

## Phase 5: User Story 3 - Complete Tasks (Priority: P1)

**Goal**: Users can mark tasks as completed

**Independent Test**: Add task, run `todo complete 1`, verify task shows as completed in list

### Tests for User Story 3

- [ ] **T-018** [P] [US3] Unit test for TaskService.complete_task() in `tests/unit/test_task_service.py`
  - Test completing incomplete task
  - Test completing already completed task raises error
  - Test completing non-existent task raises error
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-019** [US3] Integration test for complete command in `tests/integration/test_cli.py`
  - Test `todo complete 1` marks task complete
  - Test `todo complete 999` shows error
  - Test `todo complete 1` on completed task shows message
  - **Acceptance**: All tests FAIL before implementation

### Implementation for User Story 3

- [ ] **T-020** [P] [US3] Create TaskService.complete_task() in `src/services/task_service.py`
  - Validate task exists (raise TaskNotFoundError)
  - Validate task not already complete (raise TaskAlreadyCompletedError)
  - Call task.mark_complete()
  - Save updated task
  - Return updated Task
  - **Acceptance**: complete_task() marks task complete, raises appropriate errors
  - **Spec Ref**: sp.specify Â§FR-006, FR-009

- [ ] **T-021** [US3] Implement complete command handler in `src/cli/commands.py`
  - Parse task ID argument
  - Call TaskService.complete_task()
  - Display success or info message
  - Handle errors with user-friendly messages
  - **Acceptance**: `todo complete 1` marks task complete
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo complete

- [ ] **T-022** [US3] Register complete subparser in `src/cli/parser.py`
  - Add "complete" subcommand
  - Add required positional "id" argument (int)
  - **Acceptance**: `todo complete --help` shows correct usage
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo complete

**Checkpoint**: User Story 3 complete - users can complete tasks

---

## Phase 6: User Story 4 - Delete Tasks (Priority: P2)

**Goal**: Users can remove tasks from the list

**Independent Test**: Add task, run `todo delete 1`, verify task no longer appears

### Tests for User Story 4

- [ ] **T-023** [P] [US4] Unit test for TaskService.delete_task() in `tests/unit/test_task_service.py`
  - Test deleting existing task
  - Test deleting non-existent task raises error
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-024** [US4] Integration test for delete command in `tests/integration/test_cli.py`
  - Test `todo delete 1` removes task
  - Test `todo delete 999` shows error
  - **Acceptance**: All tests FAIL before implementation

### Implementation for User Story 4

- [ ] **T-025** [P] [US4] Create TaskService.delete_task() in `src/services/task_service.py`
  - Validate task exists (raise TaskNotFoundError)
  - Delete task from storage
  - **Acceptance**: delete_task() removes task, raises TaskNotFoundError if not found
  - **Spec Ref**: sp.specify Â§FR-007, FR-009

- [ ] **T-026** [US4] Implement delete command handler in `src/cli/commands.py`
  - Parse task ID argument
  - Call TaskService.delete_task()
  - Display success message
  - Handle errors
  - **Acceptance**: `todo delete 1` removes task
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo delete

- [ ] **T-027** [US4] Register delete subparser in `src/cli/parser.py`
  - Add "delete" subcommand
  - Add required positional "id" argument (int)
  - **Acceptance**: `todo delete --help` shows correct usage
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo delete

**Checkpoint**: User Story 4 complete - users can delete tasks

---

## Phase 7: User Story 5 - Update Tasks (Priority: P2)

**Goal**: Users can modify task title and description

**Independent Test**: Add task, run `todo update 1 "New title"`, verify changes in list

### Tests for User Story 5

- [ ] **T-028** [P] [US5] Unit test for TaskService.update_task() in `tests/unit/test_task_service.py`
  - Test updating title
  - Test updating description
  - Test updating title and description
  - Test updating non-existent task raises error
  - Test updating with empty title raises error
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-029** [US5] Integration test for update command in `tests/integration/test_cli.py`
  - Test `todo update 1 "New title"` updates title
  - Test `todo update 1 "New" -d "New desc"` updates both
  - Test `todo update 999 "New"` shows error
  - **Acceptance**: All tests FAIL before implementation

### Implementation for User Story 5

- [ ] **T-030** [P] [US5] Create TaskService.update_task() in `src/services/task_service.py`
  - Validate task exists (raise TaskNotFoundError)
  - Validate title if provided (raise InvalidTitleError)
  - Update title and/or description
  - Update updated_at timestamp
  - Save updated task
  - **Acceptance**: update_task() updates fields, raises appropriate errors
  - **Spec Ref**: sp.specify Â§FR-008, FR-009, FR-010

- [ ] **T-031** [US5] Implement update command handler in `src/cli/commands.py`
  - Parse task ID, title, -d/--description
  - Call TaskService.update_task()
  - Display success message
  - Handle errors
  - **Acceptance**: `todo update 1 "New title"` updates task
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo update

- [ ] **T-032** [US5] Register update subparser in `src/cli/parser.py`
  - Add "update" subcommand
  - Add required positional "id" argument
  - Add required positional "title" argument
  - Add optional -d/--description flag
  - **Acceptance**: `todo update --help` shows correct usage
  - **Spec Ref**: sp.contracts/cli-commands.md Â§Command: todo update

**Checkpoint**: User Story 5 complete - users can update tasks

---

## Phase 8: User Story 6 - Toggle Task Status (Priority: P3)

**Goal**: Users can toggle tasks between complete/incomplete states

**Independent Test**: Complete task, run `todo toggle 1`, verify task becomes incomplete

### Tests for User Story 6

- [ ] **T-033** [P] [US6] Unit test for TaskService.toggle_task() in `tests/unit/test_task_service.py`
  - Test toggling incomplete to complete
  - Test toggling complete to incomplete
  - Test toggling non-existent task raises error
  - **Acceptance**: All tests FAIL before implementation

- [ ] **T-034** [US6] Integration test for toggle command in `tests/integration/test_cli.py`
  - Test `todo toggle 1` switches status
  - Test `todo toggle 999` shows error
  - **Acceptance**: All tests FAIL before implementation

### Implementation for User Story 6

- [ ] **T-035** [P] [US6] Create TaskService.toggle_task() in `src/services/task_service.py`
  - Validate task exists (raise TaskNotFoundError)
  - Toggle completed boolean
  - Update updated_at timestamp
  - Save updated task
  - Return updated Task
  - **Acceptance**: toggle_task() inverts completed status
  - **Spec Ref**: sp.specify Â§FR-006 (extension)

- [ ] **T-036** [US6] Implement toggle command handler in `src/cli/commands.py`
  - Parse task ID argument
  - Call TaskService.toggle_task()
  - Display success message
  - Handle errors
  - **Acceptance**: `todo toggle 1` switches task status
  - **Spec Ref**: sp.specify Â§User Story 6

- [ ] **T-037** [US6] Register toggle subparser in `src/cli/parser.py`
  - Add "toggle" subcommand
  - Add required positional "id" argument (int)
  - **Acceptance**: `todo toggle --help` shows correct usage

**Checkpoint**: User Story 6 complete - users can toggle task status

---

## Phase 9: Polish & Cross-Cutting Concerns

**Purpose**: Final integration, documentation, and verification

- [ ] **T-038** [P] Implement main entry point in `src/main.py`
  - Wire together CLI parser, services, and memory
  - Implement main() function
  - Handle sys.exit() codes properly
  - **Acceptance**: `uv run src/main.py` starts application
  - **Spec Ref**: sp.plan Â§Architecture Overview

- [ ] **T-039** [P] Add help system integration in `src/cli/parser.py`
  - Ensure `todo --help` works
  - Ensure `todo <command> --help` works for all commands
  - **Acceptance**: All help commands display correct information
  - **Spec Ref**: sp.specify Â§FR-012

- [ ] **T-040** Run full test suite with coverage
  - Execute all unit tests
  - Execute all integration tests
  - Generate coverage report
  - **Acceptance**: 100% coverage on new code, all tests pass
  - **Spec Ref**: sp.constitution Â§III. TDD Mandatory

- [ ] **T-041** Create README.md documentation
  - Document setup with UV
  - Document usage with examples
  - Document all commands
  - **Acceptance**: README enables new user to run application
  - **Spec Ref**: sp.tasks Â§T-007

- [ ] **T-042** [P] Add spec traceability comments
  - Add Task ID references in all code files
  - Add spec section references in code
  - **Acceptance**: Every module references Task IDs and spec sections
  - **Spec Ref**: sp.tasks Â§T-007

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phases 3-8)**: All depend on Foundational phase completion
  - User stories can proceed in parallel (if staffed)
  - Or sequentially in priority order (P1 â†’ P2 â†’ P3)
- **Polish (Phase 9)**: Depends on all desired user stories being complete

### User Story Dependencies

- **User Story 1 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 2 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 3 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
- **User Story 4 (P2)**: Can start after Foundational (Phase 2) - Can run in parallel with US1-US3
- **User Story 5 (P2)**: Can start after Foundational (Phase 2) - Can run in parallel with US1-US4
- **User Story 6 (P3)**: Can start after Foundational (Phase 2) - Can run in parallel with all stories

### Within Each User Story

1. Write tests (ensure they FAIL)
2. Implement service method
3. Implement command handler
4. Register subparser
5. Verify tests PASS
6. Commit before moving to next story

### Parallel Opportunities

- Phase 1 tasks (T-001, T-002, T-003) can run in parallel
- Phase 2 tasks (T-004, T-005, T-006) can run in parallel
- Once Foundational completes, all user stories (US1-US6) can start in parallel
- Within each user story, unit tests, integration tests, and implementations marked [P] can run in parallel

---

## Implementation Strategy

### MVP First (P1 Stories Only)

1. Complete Phase 1: Setup
2. Complete Phase 2: Foundational
3. Complete User Stories 1, 2, 3 (P1)
4. **STOP and VALIDATE**: Test core functionality
5. Demo if ready

### Full Implementation

1. Complete Setup + Foundational â†’ Foundation ready
2. Add User Story 1 â†’ Test independently â†’ Deploy/Demo
3. Add User Story 2 â†’ Test independently â†’ Deploy/Demo
4. Add User Story 3 â†’ Test independently â†’ Deploy/Demo
5. Add User Stories 4, 5, 6 â†’ Test â†’ Deploy/Demo
6. Polish phase â†’ Final delivery

---

## Notes

- **[P]** tasks = different files, no dependencies
- **[Story]** label maps task to specific user story for traceability
- Each user story should be independently completable and testable
- Verify tests FAIL before implementing each story
- Commit after each task or logical group
- Stop at any checkpoint to validate story independently
- Avoid: vague tasks, same file conflicts, cross-story dependencies that break independence

---

## Spec References

| Reference | Description |
|-----------|-------------|
| sp.constitution | Project constitution with core principles |
| sp.specify | Feature specification with user stories and requirements |
| sp.plan | Implementation plan with architecture and technical context |
| sp.data-model.md | Detailed data model definitions |
| sp.contracts/cli-commands.md | CLI command contracts with I/O specs |
